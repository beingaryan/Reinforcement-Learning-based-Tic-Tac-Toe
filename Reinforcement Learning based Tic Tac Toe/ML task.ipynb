{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Task - 01 (The Robotics Forum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mentor Shripad Kulkarni\n",
    "#### Preeti Oswal, Aryan Gupta, Avinash Vijayvargiya\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing all required lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Developing board and funcation to game play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game:\n",
    "    def __init__(self, p1, p2):    \n",
    "        self.board = np.zeros((3, 3))\n",
    "        self.p1 = p1\n",
    "        self.p2 = p2\n",
    "        self.isEnd = False\n",
    "        self.boardHash = None\n",
    "        self.playerSymbol = 1\n",
    "    \n",
    "    \n",
    "    def getHash(self):\n",
    "        self.boardHash = str(self.board.reshape(9))\n",
    "        return self.boardHash\n",
    "    \n",
    "    \n",
    "    ## DECLARING CONDITION TO WIN THE GAME\n",
    "    def winner(self):\n",
    "        \n",
    "        ## CONDITION FOR ROWS\n",
    "        for i in range(3):\n",
    "            if sum(self.board[i, :]) == 3:\n",
    "                self.isEnd = True\n",
    "                return 1\n",
    "            if sum(self.board[i, :]) == -3:\n",
    "                self.isEnd = True\n",
    "                return -1\n",
    "            \n",
    "        ## CONDITION FOR COLUMNS\n",
    "        for i in range(3):\n",
    "            if sum(self.board[:, i]) == 3:\n",
    "                self.isEnd = True\n",
    "                return 1\n",
    "            if sum(self.board[:, i]) == -3:\n",
    "                self.isEnd = True\n",
    "                return -1\n",
    "            \n",
    "        ## CONDITION FOR DIAGONALS\n",
    "        sum1_diag = sum([self.board[i, i] for i in range(3)])\n",
    "        sum2_diag = sum([self.board[i, 3-i-1] for i in range(3)])\n",
    "        if sum1_diag == 3 or sum2_diag == 3:\n",
    "            self.isEnd = True\n",
    "            return 1\n",
    "        if sum1_diag == -3 or sum2_diag == -3:\n",
    "            self.isEnd = True\n",
    "            return -1\n",
    "        if len(self.remainingPositions()) == 0:\n",
    "            self.isEnd = True\n",
    "            return 0\n",
    "        self.isEnd = False\n",
    "        return None\n",
    "    \n",
    "    ## FUNCTION TO DETERMINE VACANT POSITIONS\n",
    "    def remainingPositions(self):\n",
    "        positions = []\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if self.board[i, j] == 0:\n",
    "                    positions.append((i, j))\n",
    "        return positions\n",
    "    \n",
    "    ## FUNCTION TO UPDATE BOARD VALUES\n",
    "    def update(self, position):\n",
    "        self.board[position] = self.playerSymbol\n",
    "        self.playerSymbol = -1 if self.playerSymbol == 1 else 1\n",
    "    \n",
    "    \n",
    "    ##  FUNCTION TO REWARD MACHINE\n",
    "    def giveReward(self):\n",
    "        result = self.winner()\n",
    "        if result == 1:\n",
    "            self.p1.feedReward(1)\n",
    "            self.p2.feedReward(0)\n",
    "        elif result == -1:\n",
    "            self.p1.feedReward(0)\n",
    "            self.p2.feedReward(1)\n",
    "        else:\n",
    "            self.p1.feedReward(0.1)\n",
    "            self.p2.feedReward(0.5)\n",
    "    \n",
    "    ## FUNCTION TO RESET THE BOARD FOR THE GAME\n",
    "    def reset(self):\n",
    "        self.board = np.zeros((3,3))\n",
    "        self.boardHash = None\n",
    "        self.isEnd = False\n",
    "        self.playerSymbol = 1\n",
    "        \n",
    "    ## FUNCTION FOR PLAYER 1 AND PLAYER 2\n",
    "    def play(self, rounds=100):\n",
    "        for i in range(rounds):\n",
    "            while not self.isEnd:\n",
    "                positions = self.remainingPositions()\n",
    "                p1_action = self.p1.NextMove(positions, self.board, self.playerSymbol)\n",
    "                self.update(p1_action)\n",
    "                board_hash = self.getHash()\n",
    "                self.p1.addState(board_hash)\n",
    "                win = self.winner()\n",
    "                if win is not None:\n",
    "                    self.giveReward()\n",
    "                    self.p1.reset()\n",
    "                    self.p2.reset()\n",
    "                    self.reset()\n",
    "                    break\n",
    "\n",
    "                else:\n",
    "                    positions = self.remainingPositions()\n",
    "                    p2_action = self.p2.NextMove(positions, self.board, self.playerSymbol)\n",
    "                    self.update(p2_action)\n",
    "                    board_hash = self.getHash()\n",
    "                    self.p2.addState(board_hash)\n",
    "                    \n",
    "                    win = self.winner()\n",
    "                    if win is not None:\n",
    "                        self.giveReward()\n",
    "                        self.p1.reset()\n",
    "                        self.p2.reset()\n",
    "                        self.reset()\n",
    "                        break\n",
    "    \n",
    "    def play2(self):\n",
    "        while not self.isEnd:\n",
    "            positions = self.remainingPositions()\n",
    "            p1_action = self.p1.NextMove(positions, self.board, self.playerSymbol)\n",
    "            self.update(p1_action)\n",
    "            self.Display()\n",
    "            win = self.winner()\n",
    "            if win is not None:\n",
    "                if win == 1:\n",
    "                    print(self.p1.name, \"Wins! , Better Luck next time\")\n",
    "                else:\n",
    "                    print(\"Tie!\")\n",
    "                self.reset()\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                positions = self.remainingPositions()\n",
    "                p2_action = self.p2.NextMove(positions)\n",
    "                self.update(p2_action)\n",
    "                self.Display()\n",
    "                win = self.winner()\n",
    "                if win is not None:\n",
    "                    if win == -1:\n",
    "                        print(self.p2.name, \"Win!\")\n",
    "                    else:\n",
    "                        print(\"Tie!\")\n",
    "                    self.reset()\n",
    "                    break\n",
    "\n",
    "    def Display(self):\n",
    "        for i in range(0, 3):\n",
    "            print('-------------')\n",
    "            out = '| '\n",
    "            for j in range(0, 3):\n",
    "                if self.board[i, j] == 1:\n",
    "                    token = 'X'\n",
    "                if self.board[i, j] == -1:\n",
    "                    token = 'O'\n",
    "                if self.board[i, j] == 0:\n",
    "                    token = ' '\n",
    "                out += token + ' | '\n",
    "            print(out)\n",
    "        print('-------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating self-learning machine model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, name, random=0.3):\n",
    "        self.name = name\n",
    "        self.states = []\n",
    "        self.random = random\n",
    "        self.lr = 0.2\n",
    "        self.states_value = {}\n",
    "    \n",
    "    def getHash(self, board):\n",
    "        boardHash = str(board.reshape(9))\n",
    "        return boardHash\n",
    "    \n",
    "    def NextMove(self, positions, current_board, symbol):\n",
    "        if np.random.uniform(0, 1) <= self.random:\n",
    "            idx = np.random.choice(len(positions))\n",
    "            action = positions[idx]\n",
    "        else:\n",
    "            value_max = -999\n",
    "            for p in positions:\n",
    "                next_board = current_board.copy()\n",
    "                next_board[p] = symbol\n",
    "                next_boardHash = self.getHash(next_board)\n",
    "                value = 0 if self.states_value.get(next_boardHash) is None else self.states_value.get(next_boardHash)\n",
    "                if value >= value_max:\n",
    "                    value_max = value\n",
    "                    action = p\n",
    "        return action\n",
    "    \n",
    "    def addState(self, state):\n",
    "        self.states.append(state)\n",
    "    \n",
    "    def feedReward(self, reward):\n",
    "        for st in reversed(self.states):\n",
    "            if self.states_value.get(st) is None:\n",
    "                self.states_value[st] = 0\n",
    "            self.states_value[st] += self.lr*(0.9*reward - self.states_value[st])\n",
    "            reward = self.states_value[st]\n",
    "            \n",
    "    def reset(self):\n",
    "        self.states = []\n",
    "        \n",
    "    def saveDict(self):\n",
    "        fw = open('policy_' + str(self.name), 'wb')\n",
    "        pickle.dump(self.states_value, fw)\n",
    "        fw.close()\n",
    "\n",
    "    def loadDict(self, file):\n",
    "        fr = open(file,'rb')\n",
    "        self.states_value = pickle.load(fr)\n",
    "        fr.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When Human is player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Human:\n",
    "    def __init__(self, name):\n",
    "        self.name = name \n",
    "    def NextMove(self, positions):\n",
    "        while True:\n",
    "            row = int(input(\"Input your action row:\"))\n",
    "            col = int(input(\"Input your action col:\"))\n",
    "            action = (row, col)\n",
    "            if action in positions:\n",
    "                return action\n",
    "    def addState(self, state):\n",
    "        pass\n",
    "    def feedReward(self, reward):\n",
    "        pass      \n",
    "    def reset(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n"
     ]
    }
   ],
   "source": [
    "p1 = Model(\"p1\")\n",
    "p2 = Model(\"p2\")\n",
    "\n",
    "st = Game(p1, p2)\n",
    "print(\"training...\")\n",
    "st.play(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1.saveDict()\n",
    "p2.saveDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1.loadDict(\"policy_p1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   | X |   | \n",
      "-------------\n",
      "Input your action row:0\n",
      "Input your action col:1\n",
      "-------------\n",
      "|   | O |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   | X |   | \n",
      "-------------\n",
      "-------------\n",
      "|   | O |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   | X | X | \n",
      "-------------\n",
      "Input your action row:0\n",
      "Input your action col:2\n",
      "-------------\n",
      "|   | O | O | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   | X | X | \n",
      "-------------\n",
      "-------------\n",
      "|   | O | O | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "| X | X | X | \n",
      "-------------\n",
      "computer Wins! , Better Luck next time\n"
     ]
    }
   ],
   "source": [
    "p1 = Model(\"computer\" , 0)\n",
    "p1.loadDict(\"policy_p1\")\n",
    "\n",
    "p2 = Human(\"You\")\n",
    "st = Game(p1, p2)\n",
    "st.play2()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
